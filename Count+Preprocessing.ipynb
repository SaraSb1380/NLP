{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# Import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SCENE 1: [wind] [clop clop clop] KING ARTHUR: Whoa there!  [clop clop clop] SOLDIER #1: Halt!  Who goes there? ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!SOLDIER #1: Pull the other one! ARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.SOLDIER #1: What?  Ridden on a horse? ARTHUR: Yes!'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article='SCENE 1: [wind] [clop clop clop] KING ARTHUR: Whoa there!  [clop clop clop] SOLDIER #1: Halt!  Who goes there? ARTHUR: It is I, Arthur, son of Uther Pendragon, from the castle of Camelot.  King of the Britons, defeator of the Saxons, sovereign of all England!SOLDIER #1: Pull the other one! ARTHUR: I am, ...  and this is my trusty servant Patsy.  We have ridden the length and breadth of the land in search of knights who will join me in my court at Camelot.  I must speak with your lord and master.SOLDIER #1: What?  Ridden on a horse? ARTHUR: Yes!'\n",
    "article\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop', ']', 'king', 'arthur', ':', 'whoa', 'there', '!', '[', 'clop', 'clop', 'clop', ']', 'soldier', '#', '1', ':', 'halt', '!', 'who', 'goes', 'there', '?', 'arthur', ':', 'it', 'is', 'i', ',', 'arthur', ',', 'son', 'of', 'uther', 'pendragon', ',', 'from', 'the', 'castle', 'of', 'camelot', '.', 'king', 'of', 'the', 'britons', ',', 'defeator', 'of', 'the', 'saxons', ',', 'sovereign', 'of', 'all', 'england', '!', 'soldier', '#', '1', ':', 'pull', 'the', 'other', 'one', '!', 'arthur', ':', 'i', 'am', ',', '...', 'and', 'this', 'is', 'my', 'trusty', 'servant', 'patsy', '.', 'we', 'have', 'ridden', 'the', 'length', 'and', 'breadth', 'of', 'the', 'land', 'in', 'search', 'of', 'knights', 'who', 'will', 'join', 'me', 'in', 'my', 'court', 'at', 'camelot', '.', 'i', 'must', 'speak', 'with', 'your', 'lord', 'and', 'master.soldier', '#', '1', ':', 'what', '?', 'ridden', 'on', 'a', 'horse', '?', 'arthur', ':', 'yes', '!']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the article: tokens. Convert the tokens into lowercase: lower_tokens\n",
    "lower_tokens = word_tokenize(article.lower())\n",
    "print(lower_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list just the alphabetical tokens, remove digits and punctuations \n",
    "alpha_only = [l for l in lower_tokens if l.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove all stop words: no_stops\n",
    "english_stops=stopwords.words('english')\n",
    "no_stops = [t for t in alpha_only if t not in english_stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "lemmatization reduces the word-forms to linguistically valid lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### word lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate the WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene', 'wind', 'clop', 'clop', 'clop', 'king', 'arthur', 'whoa', 'clop', 'clop', 'clop', 'soldier', 'halt', 'go', 'arthur', 'arthur', 'son', 'uther', 'pendragon', 'castle', 'camelot', 'king', 'briton', 'defeator', 'saxon', 'sovereign', 'england', 'soldier', 'pull', 'one', 'arthur', 'trusty', 'servant', 'patsy', 'ridden', 'length', 'breadth', 'land', 'search', 'knight', 'join', 'court', 'camelot', 'must', 'speak', 'lord', 'ridden', 'horse', 'arthur', 'yes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Lemmatize all tokens into a new list: lemmatized\n",
    "lemmatized = [wordnet_lemmatizer.lemmatize(t) for t in no_stops]\n",
    "print(lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the bag-of-words: bow\n",
    "bow = Counter(lemmatized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clop', 6), ('arthur', 5), ('king', 2), ('soldier', 2), ('camelot', 2), ('ridden', 2), ('scene', 1), ('wind', 1), ('whoa', 1), ('halt', 1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the 10 most common tokens\n",
    "print(bow.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line Lemmatization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pywsd\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/bb/427a49c461b0970c124509f77d2cd75bdca0daa746155c45d065f0af93e3/pywsd-1.2.4.tar.gz (26.8MB)\n",
      "\u001b[K     |████████████████████████████████| 26.8MB 16.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk in /opt/anaconda3/lib/python3.7/site-packages (from pywsd) (3.5)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from pywsd) (1.17.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from pywsd) (0.25.3)\n",
      "Collecting wn (from pywsd)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/f6/72db36e8afc977ae1a1cbb22afc77fd9b514e9bc6927ae8f4aae36665961/wn-0.0.23.tar.gz (31.6MB)\n",
      "\u001b[K     |████████████████████████████████| 31.6MB 25.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from pywsd) (1.12.0)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from nltk->pywsd) (0.14.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from nltk->pywsd) (4.42.0)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.7/site-packages (from nltk->pywsd) (2020.6.8)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.7/site-packages (from nltk->pywsd) (7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->pywsd) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas->pywsd) (2019.3)\n",
      "Building wheels for collected packages: pywsd, wn\n",
      "  Building wheel for pywsd (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pywsd: filename=pywsd-1.2.4-cp37-none-any.whl size=26940454 sha256=a20b19d69c5f632e4bd18e85619041d5596b51254e31bf7b868c24e5a398ab75\n",
      "  Stored in directory: /Users/sarasaberiyanboroujeni/Library/Caches/pip/wheels/71/4d/d2/405b948047f7f3851f16ab9d893ce7c1a3010182900884536b\n",
      "  Building wheel for wn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wn: filename=wn-0.0.23-cp37-none-any.whl size=31792943 sha256=0596d0e23ad0bf2ea5e895c994bb7c24492dc47f8d495b057e436ea657d17f38\n",
      "  Stored in directory: /Users/sarasaberiyanboroujeni/Library/Caches/pip/wheels/56/e3/c4/886021dbf4d758dc3cb9ddaa47d7d6fc895240d83f010e6305\n",
      "Successfully built pywsd wn\n",
      "Installing collected packages: wn, pywsd\n",
      "Successfully installed pywsd-1.2.4 wn-0.0.23\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install pywsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywsd.utils import lemmatize_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word lemmatization is one method of lemmetizing the text. But in some cases it doesn't work well like finding \n",
    "the lemma of leaves in the below sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mary', 'leave', 'the', 'room']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_sentence(\"Mary leaves the room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=word_tokenize((\"Mary leaves the room\").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mary', 'leaf', 'the', 'room']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[wordnet_lemmatizer.lemmatize(test) for test in word_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### line lemmatization of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tokens=word_tokenize(article.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scene 1: [wind] [clop clop clop] king arthur: whoa there!',\n",
       " '[clop clop clop] soldier #1: halt!',\n",
       " 'who goes there?',\n",
       " 'arthur: it is i, arthur, son of uther pendragon, from the castle of camelot.',\n",
       " 'king of the britons, defeator of the saxons, sovereign of all england!soldier #1: pull the other one!',\n",
       " 'arthur: i am, ...  and this is my trusty servant patsy.',\n",
       " 'we have ridden the length and breadth of the land in search of knights who will join me in my court at camelot.',\n",
       " 'i must speak with your lord and master.soldier #1: what?',\n",
       " 'ridden on a horse?',\n",
       " 'arthur: yes!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['scene', '1', ':', '[', 'wind', ']', '[', 'clop', 'clop', 'clop', ']', 'king', 'arthur', ':', 'whoa', 'there', '!', '[', 'clop', 'clop', 'clop', ']', 'soldier', '#', '1', ':', 'halt', '!', 'who', 'go', 'there', '?', 'arthur', ':', 'it', 'be', 'i', ',', 'arthur', ',', 'son', 'of', 'uther', 'pendragon', ',', 'from', 'the', 'castle', 'of', 'camelot', '.', 'king', 'of', 'the', 'briton', ',', 'defeat', 'of', 'the', 'saxon', ',', 'sovereign', 'of', 'all', 'england', '!', 'soldier', '#', '1', ':', 'pull', 'the', 'other', 'one', '!', 'arthur', ':', 'i', 'be', ',', '...', 'and', 'this', 'be', 'my', 'trusty', 'servant', 'patsy', '.', 'we', 'have', 'ride', 'the', 'length', 'and', 'breadth', 'of', 'the', 'land', 'in', 'search', 'of', 'knight', 'who', 'will', 'join', 'me', 'in', 'my', 'court', 'at', 'camelot', '.', 'i', 'must', 'speak', 'with', 'your', 'lord', 'and', 'master.soldier', '#', '1', ':', 'what', '?', 'ridden', 'on', 'a', 'horse', '?', 'arthur', ':', 'yes', '!']\n"
     ]
    }
   ],
   "source": [
    "lemmatize_line=lemmatize_sentence(article)\n",
    "print(lemmatize_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
